# Gradient Descent for Linear Regression ğŸ“‰

This project demonstrates a custom implementation of the **gradient descent algorithm** for solving a **linear regression** problem, applied to the **Iris dataset**.  
Developed as part of the **MeIA 2025** final project.

## ğŸ¯ Objective

To implement linear regression from scratch using NumPy and optimize the model using gradient descent â€” without relying on libraries like scikit-learn.

## ğŸ“Š Dataset

- Dataset: [Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)
- Independent variables: `sepal_width`, `petal_width`, `sepal_length`
- Dependent variable: `petal_length`

## ğŸ” Methodology

- Manual implementation of gradient descent
- Cost function: Mean Squared Error (MSE)
- Comparison with scikit-learn's `LinearRegression`
- Visualization of training progress and predictions

## ğŸ“ˆ Results

- Cost reduced from `3.14` to `~0.05` after 1000 iterations
- Manual model yielded parameters close to those from scikit-learn
- Clear match between predicted and real values in plots

## ğŸ“ Key Libraries

- NumPy
- pandas
- matplotlib
- scikit-learn (for validation only)

## ğŸ§  Author

- JesÃºs Antonio Torres Contreras

## ğŸ“„ License

MIT License â€“ see [`LICENSE`](./LICENSE)

